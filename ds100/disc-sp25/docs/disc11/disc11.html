<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>12&nbsp; Logistic Regression – Data 100 Discussion Notes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../disc10/disc10.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-ca5a086e270bb62b76934925835b48c3.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../disc11/disc11.html"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Logistic Regression</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Data 100 Discussion Notes</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">disc-sp25</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../disc01/disc01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Math Prerequisites</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../disc02/disc02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Pandas I</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../disc03/disc03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Pandas II, EDA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../disc04/disc04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Regex, Visualization, and Transformation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../disc05/disc05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Transformations, Sampling, and SLR</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../disc06/disc06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Models, OLS</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../disc07/disc07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Gradient Descent, Feature Engineering, Housing</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../disc08/disc08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Cross-Validation and Regularization</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../disc09/disc09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Bias and Variance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../disc10/disc10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">SQL (will update once code works)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../disc11/disc11.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Logistic Regression</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Logistic Regression</h2>
   
  <ul>
  <li><a href="#link-to-slides" id="toc-link-to-slides" class="nav-link active" data-scroll-target="#link-to-slides"><span class="header-section-number">12.1</span> Link to Slides</a></li>
  <li><a href="#logistic-regression" id="toc-logistic-regression" class="nav-link" data-scroll-target="#logistic-regression"><span class="header-section-number">12.2</span> Logistic Regression</a>
  <ul class="collapse">
  <li><a href="#a" id="toc-a" class="nav-link" data-scroll-target="#a"><span class="header-section-number">12.2.1</span> (a)</a></li>
  <li><a href="#b" id="toc-b" class="nav-link" data-scroll-target="#b"><span class="header-section-number">12.2.2</span> (b)</a></li>
  <li><a href="#c" id="toc-c" class="nav-link" data-scroll-target="#c"><span class="header-section-number">12.2.3</span> (c)</a></li>
  <li><a href="#d" id="toc-d" class="nav-link" data-scroll-target="#d"><span class="header-section-number">12.2.4</span> (d)</a></li>
  </ul></li>
  <li><a href="#linearly-separable-data" id="toc-linearly-separable-data" class="nav-link" data-scroll-target="#linearly-separable-data"><span class="header-section-number">12.3</span> Linearly Separable Data</a>
  <ul class="collapse">
  <li><a href="#a-1" id="toc-a-1" class="nav-link" data-scroll-target="#a-1"><span class="header-section-number">12.3.1</span> (a)</a></li>
  <li><a href="#b-1" id="toc-b-1" class="nav-link" data-scroll-target="#b-1"><span class="header-section-number">12.3.2</span> (b)</a></li>
  <li><a href="#c-1" id="toc-c-1" class="nav-link" data-scroll-target="#c-1"><span class="header-section-number">12.3.3</span> (c)</a></li>
  </ul></li>
  <li><a href="#roc-curves" id="toc-roc-curves" class="nav-link" data-scroll-target="#roc-curves"><span class="header-section-number">12.4</span> ROC Curves</a>
  <ul class="collapse">
  <li><a href="#a-2" id="toc-a-2" class="nav-link" data-scroll-target="#a-2"><span class="header-section-number">12.4.1</span> (a)</a></li>
  <li><a href="#b-2" id="toc-b-2" class="nav-link" data-scroll-target="#b-2"><span class="header-section-number">12.4.2</span> (b)</a></li>
  </ul></li>
  <li><a href="#performance-metrics" id="toc-performance-metrics" class="nav-link" data-scroll-target="#performance-metrics"><span class="header-section-number">12.5</span> Performance Metrics</a>
  <ul class="collapse">
  <li><a href="#a-3" id="toc-a-3" class="nav-link" data-scroll-target="#a-3"><span class="header-section-number">12.5.1</span> (a)</a></li>
  <li><a href="#b-3" id="toc-b-3" class="nav-link" data-scroll-target="#b-3"><span class="header-section-number">12.5.2</span> (b)</a></li>
  <li><a href="#c-2" id="toc-c-2" class="nav-link" data-scroll-target="#c-2"><span class="header-section-number">12.5.3</span> (c)</a></li>
  <li><a href="#d-1" id="toc-d-1" class="nav-link" data-scroll-target="#d-1"><span class="header-section-number">12.5.4</span> (d)</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Logistic Regression</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta column-body">

    
  
    
  </div>
  


</header>


<section id="link-to-slides" class="level2" data-number="12.1">
<h2 data-number="12.1" class="anchored" data-anchor-id="link-to-slides"><span class="header-section-number">12.1</span> <a href="https://docs.google.com/presentation/d/1Uity00kUjV7JK2PUXR3LvIb0tIxF2y74bGXA4pYGwOg/edit?usp=sharing">Link to Slides</a></h2>
</section>
<section id="logistic-regression" class="level2" data-number="12.2">
<h2 data-number="12.2" class="anchored" data-anchor-id="logistic-regression"><span class="header-section-number">12.2</span> Logistic Regression</h2>
<p>Suppose we are given the following dataset, with two features (<span class="math inline">\(\Bbb{X}_{:, 0}\)</span> and <span class="math inline">\(\Bbb{X}_{:, 1}\)</span>) and one binary response variable (<span class="math inline">\(y\)</span>)</p>
<center>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;"><span class="math inline">\(\mathbb{X}_{:, 0}\)</span></th>
<th style="text-align: center;"><span class="math inline">\(\mathbb{X}_{:, 1}\)</span></th>
<th style="text-align: center;"><span class="math inline">\(y\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">2</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">-1</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
</center>
<p>Here, <span class="math inline">\(\vec{x}^T\)</span> corresponds to a single row of our data matrix, not including the <span class="math inline">\(y\)</span> column. Thus, we can write <span class="math inline">\(\vec{x}_1^T\)</span> as <span class="math inline">\(\vec{x}_1^T = \left[2 \quad 2\right]\)</span>. Note that there is no intercept term!</p>
<p>Suppose you run a Logistic Regression model to determine the probability that <span class="math inline">\(Y=1\)</span> given <span class="math inline">\(\vec{x}\)</span>. We denote probability as <span class="math inline">\(P_{\hat{\theta}}\)</span> as opposed to just <span class="math inline">\(P\)</span> to show that <span class="math inline">\(\hat{\theta}\)</span> is a like it is in OLS, where we denote our function as <span class="math inline">\(f_{\theta}(x)\)</span>.</p>
<p><span class="math display">\[P_{\hat{\theta}}(Y=1|\vec{x}) = \sigma(\vec{x}^T \theta) = \frac{1}{1 + \exp(- \vec{x}^T \theta)}\]</span></p>
<p>Your algorithm learns that the optimal <span class="math inline">\(\hat\theta\)</span> value is <span class="math inline">\(\hat\theta = \left[-\frac{1}{2} \quad-\frac{1}{2}\right]^T\)</span>.</p>
<section id="a" class="level3" data-number="12.2.1">
<h3 data-number="12.2.1" class="anchored" data-anchor-id="a"><span class="header-section-number">12.2.1</span> (a)</h3>
<p><span class="math inline">\(\sigma(z)\)</span> is called a “sigmoid” function with the equation <span class="math display">\[\sigma(z) = \frac{1}{1 + \exp(-z)}\]</span> for some arbitrary real number <span class="math inline">\(z\)</span>. What is the range of possible values for <span class="math inline">\(\sigma(\cdot)\)</span>?</p>
<details>
<summary>
<b>Answer</b>
</summary>
<ul>
<li><p><span class="math inline">\(x \to -\infty: \frac{1}{1 + e^{-z}} \to 0\)</span></p></li>
<li><p><span class="math inline">\(x \to \infty: \frac{1}{1 + e^{-z}} \to \frac{1}{1 + 0} = 1\)</span></p></li>
</ul>
<p><span class="math inline">\(0 &lt; \sigma(z) &lt; 1\)</span>. Note that the sigmoid function can never <em>equal</em> 0 or 1.</p>
</details>
</section>
<section id="b" class="level3" data-number="12.2.2">
<h3 data-number="12.2.2" class="anchored" data-anchor-id="b"><span class="header-section-number">12.2.2</span> (b)</h3>
<p>Calculate <span class="math inline">\(P_{\hat{\theta}}(Y=1|\vec{x}^T=\left[1 \quad   0\right])\)</span>.</p>
<details>
<summary>
<b>Answer</b>
</summary>
<p>Calculate <span class="math inline">\(\vec{x}^T\hat{\theta}\)</span> first:</p>
<p><span class="math display">\[\begin{align*}
    \vec{x}^T\hat{\theta} &amp;= \begin{bmatrix}1 &amp; 0\end{bmatrix}\begin{bmatrix} -\frac{1}{2} \\ -\frac{1}{2} \end{bmatrix}\\
    &amp;= 1*-\frac{1}{2} + 0*-\frac{1}{2}\\
    &amp;= -\frac{1}{2}
\end{align*}\]</span></p>
<p>We can then plug this into the sigmoid function:</p>
<p><span class="math display">\[\begin{align*}
    \sigma(-\frac{1}{2}) &amp;= \frac{1}{1 + e^{\frac{1}{2}}}\\
    &amp;\approx 0.38
\end{align*}\]</span></p>
</details>
</section>
<section id="c" class="level3" data-number="12.2.3">
<h3 data-number="12.2.3" class="anchored" data-anchor-id="c"><span class="header-section-number">12.2.3</span> (c)</h3>
<p>Using a threshold of <span class="math inline">\(T = 0.5\)</span>, what would our algorithm classify <span class="math inline">\(y\)</span> as given the results of part b?</p>
<details>
<summary>
<b>Answer</b>
</summary>
<p>Our <span class="math inline">\(p\)</span> of <span class="math inline">\(0.38\)</span> is <em>smaller</em> than the threshold of <span class="math inline">\(0.5\)</span>, so our algorithm would classify <span class="math inline">\(y\)</span> as class <span class="math inline">\(0\)</span>.</p>
<p>A <strong>Decision Rule</strong> tells us how to classify a data point:</p>
<p><span class="math display">\[\hat{y} =
\begin{cases}
\text{Class 1} &amp;\text{if } \quad p \geq T\\
\text{Class 0} &amp;\text{if } \quad p \lt T
\end{cases}
\]</span></p>
</details>
</section>
<section id="d" class="level3" data-number="12.2.4">
<h3 data-number="12.2.4" class="anchored" data-anchor-id="d"><span class="header-section-number">12.2.4</span> (d)</h3>
<p>The empirical risk using cross-entropy loss is given by the following expression. Remember, whenever you see <span class="math inline">\(\log\)</span> in this course, you must assume the natural logarithm (base-<span class="math inline">\(e\)</span>) unless explicitly told otherwise.</p>
<p><span class="math display">\[\begin{align*}
    R(\theta) &amp;= -\dfrac{1}{n} \sum_{i=1}^{n} \big( y_i \log P_{\theta}(Y=1|\vec{x_i}) + (1-y_i) \log  P_{\theta}(Y=0|\vec{x_i}) \big)
\end{align*}\]</span></p>
<p>Suppose we run a different algorithm and obtain <span class="math inline">\(\hat\theta_{new} = \left[0 \quad 0\right]^T\)</span>. Calculate the empirical risk for <span class="math inline">\(\hat\theta_{new}\)</span> on our dataset.</p>
<details>
<summary>
<b>Answer</b>
</summary>
<p><span class="math display">\[\begin{align*}
    R(\hat\theta_{new}) &amp;= -\dfrac{1}{2} \sum_{i=1}^{2} \big( y_i \log P_{\hat{\theta_{new}}}(Y=1|\vec{x_i}) + (1-y_i) \log  P_{\hat{\theta_{new}}}(Y=0|\vec{x_i}) )\\
    &amp;= -\frac{1}{2} [(0 \log P_{\hat{\theta_{new}}}(Y=1|\vec{x_1}) + 1 \log  P_{\hat{\theta_{new}}}(Y=0|\vec{x_1})) + \\ &amp; (1 \log P_{\hat{\theta_{new}}}(Y=1|\vec{x_2}) + 0 \log  P_{\hat{\theta_{new}}}(Y=0|\vec{x_2}))] \\
    &amp;= -\frac{1}{2} (\log P_{\hat{\theta_{new}}}(Y=0|\vec{x_1}) + \log P_{\hat{\theta_{new}}}(Y=1|\vec{x_2})) \\
    &amp;= -\frac{1}{2} (\log (1 - \sigma(0)) + \log \sigma(0)) \\
    &amp;= -\log(0.5) = \log 2 \approx 0.693
\end{align*}\]</span></p>
<p>Notice that the inputs to the sigmoid function are <span class="math inline">\(0\)</span> because <span class="math inline">\(\hat{\theta}_{new}\)</span> is the zero vector, making all <span class="math inline">\(\vec{x}^T\hat{\theta}_{new} = 0\)</span></p>
</details>
</section>
</section>
<section id="linearly-separable-data" class="level2" data-number="12.3">
<h2 data-number="12.3" class="anchored" data-anchor-id="linearly-separable-data"><span class="header-section-number">12.3</span> Linearly Separable Data</h2>
<p>Suppose we have two different Logistic Regression models, A and B, and we run gradient descent for 1000 steps to obtain the model parameters <span class="math inline">\(\hat\theta_A = \left[-\frac{1}{2} \quad-\frac{1}{2}\right]^T\)</span> and <span class="math inline">\(\hat\theta_B = \left[0 \quad0\right]^T\)</span>. How do they compare?</p>
<p>The dataset is reproduced below for your convenience.</p>
<center>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;"><span class="math inline">\(\mathbb{X}_{:, 0}\)</span></th>
<th style="text-align: center;"><span class="math inline">\(\mathbb{X}_{:, 1}\)</span></th>
<th style="text-align: center;"><span class="math inline">\(y\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">2</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">-1</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
</center>
<section id="a-1" class="level3" data-number="12.3.1">
<h3 data-number="12.3.1" class="anchored" data-anchor-id="a-1"><span class="header-section-number">12.3.1</span> (a)</h3>
<p>Is our dataset linearly separable? If so, write the equation of a hyperplane that separates the two classes. Otherwise, briefly explain why not (Hint: draw the two data points).</p>
<details>
<summary>
<b>Answer</b>
</summary>
<p>Yes, the line <span class="math inline">\(\mathbb{X}_{:, 1} = 0\)</span> (line on horizontal axis) separates the data in feature space!</p>
<center>
<img src="images/q2a.png" width="500">
</center>
</details>
</section>
<section id="b-1" class="level3" data-number="12.3.2">
<h3 data-number="12.3.2" class="anchored" data-anchor-id="b-1"><span class="header-section-number">12.3.2</span> (b)</h3>
<p>If we let gradient descent keep running indefinitely for our two models, will either of them converge given the design matrix above? Why? If not, how can we remedy this?</p>
<details>
<summary>
<b>Answer</b>
</summary>
<p>No.</p>
<p>Our dataset is linearly separable, so the <em>optimal</em> cross-entropy loss is 0. However, a cross-entropy loss of 0 can never be achieved. Remember that <span class="math inline">\(\sigma(z)\)</span> never outputs <em>exactly</em> 0 or 1, but it can get arbitrarily close!</p>
<p>Hence, no single value of <span class="math inline">\(\theta\)</span> will ever “minimize” cross-entropy loss (ie. let <span class="math inline">\(\sigma(x^T \theta) = 0\)</span>), but gradient descent can bring the cross-entropy loss closer and closer to 0 as <span class="math inline">\(\theta\)</span> goes to <span class="math inline">\(\pm \infty\)</span>.</p>
<p>To avoid our absolute values of the weights diverging to <span class="math inline">\(\infty\)</span>, we can regularize our cross-entropy loss and penalize arbitrarily large <span class="math inline">\(\theta\)</span>!</p>
</details>
</section>
<section id="c-1" class="level3" data-number="12.3.3">
<h3 data-number="12.3.3" class="anchored" data-anchor-id="c-1"><span class="header-section-number">12.3.3</span> (c)</h3>
<p>Assume we add the data point <span class="math inline">\([3, -2]\)</span> to the design matrix such that our resulting design matrix is as follows:</p>
<center>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;"><span class="math inline">\(\mathbb{X}_{:, 0}\)</span></th>
<th style="text-align: center;"><span class="math inline">\(\mathbb{X}_{:, 1}\)</span></th>
<th style="text-align: center;"><span class="math inline">\(y\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">2</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">-1</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3</td>
<td style="text-align: center;">-2</td>
<td style="text-align: center;">0</td>
</tr>
</tbody>
</table>
</center>
<p>Is it possible to achive a perfect accuracy using logistic regression?</p>
<details>
<summary>
<b>Answer</b>
</summary>
<p>The data is still linearly separable, so we can train a logistic regression model to achieve perfect accuracy! For example, <span class="math inline">\(\mathbb{X}_{:, 0} = 1.5\)</span> would result in perfect accuracy.</p>
<center>
<img src="images/q2c.png" width="500">
</center>
</details>
</section>
</section>
<section id="roc-curves" class="level2" data-number="12.4">
<h2 data-number="12.4" class="anchored" data-anchor-id="roc-curves"><span class="header-section-number">12.4</span> ROC Curves</h2>
<p>Consider the following ROC (receiver operating characteristic) curves that were each created from different models.</p>
<center>
<img src="images/roc.png" width="500">
</center>
<section id="a-2" class="level3" data-number="12.4.1">
<h3 data-number="12.4.1" class="anchored" data-anchor-id="a-2"><span class="header-section-number">12.4.1</span> (a)</h3>
<p>Compare the Area Under the Curve (AUC) of Line 1 and Line 4. What kind of model would predict Line 1? What kind of model would predict Line 4?</p>
<details>
<summary>
<b>Answer</b>
</summary>
<p>Line 1 (solid black line) is known as a “perfect predictor”; it always predicts the correct class for <span class="math inline">\(y\)</span>, so its true positive rate (TPR) is 1, and its false positive rate (FPR) is 0. Because we want our classifier to be as close as possible to the perfect predictor, we aim to maximize the AUC.</p>
<p>On the other hand, Line 4 (solid grey line) is a random predictor that predicts <span class="math inline">\(y=1\)</span> with a probability of 0.5 and <span class="math inline">\(y=0\)</span> with a probability of 0.5. It’s AUC = 0.5, and it does no better than a random coin flip (proof in course notes).</p>
</details>
</section>
<section id="b-2" class="level3" data-number="12.4.2">
<h3 data-number="12.4.2" class="anchored" data-anchor-id="b-2"><span class="header-section-number">12.4.2</span> (b)</h3>
<p>Suppose we fix the decision threshold for all 4 models such that we get an FPR of 0.1 when we evaluate our model. In order of most to least preferred, rank models given their ROC curve.</p>
<details>
<summary>
<b>Answer</b>
</summary>
<p>Since the FPR is now fixed at 0.1, the only thing that we can adjust is the TPR. To determine the most to least preferred model, we look at each model’s TPR at an FPR of 0.1. Higher TPRs are better because they indicate that a greater proportion of true positive cases are correctly identified by the model. Hence, we get the following ranking: <span class="math display">\[\text{Line 1} &gt; \text{Line 3} &gt;\text{Line 2} &gt;\text{Line 4} \]</span></p>
</details>
</section>
</section>
<section id="performance-metrics" class="level2" data-number="12.5">
<h2 data-number="12.5" class="anchored" data-anchor-id="performance-metrics"><span class="header-section-number">12.5</span> Performance Metrics</h2>
<p>Here are some classification performance metrics (from Fall 2023 Final Reference Sheet):</p>
<center>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Metric</th>
<th style="text-align: center;">Formula</th>
<th style="text-align: center;">Other Names</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Accuracy</td>
<td style="text-align: center;"><span class="math inline">\(\frac{TP+TN}{n}\)</span></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">Precision</td>
<td style="text-align: center;"><span class="math inline">\(\frac{TP}{TP + FP}\)</span></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">Recall/TPR</td>
<td style="text-align: center;"><span class="math inline">\(\frac{TP}{TP + FN}\)</span></td>
<td style="text-align: center;">True Positive Rate, Sensitivity</td>
</tr>
<tr class="even">
<td style="text-align: center;">FPR</td>
<td style="text-align: center;"><span class="math inline">\(\frac{FP}{FP + TN}\)</span></td>
<td style="text-align: center;">False Positive Rate, Specificity</td>
</tr>
</tbody>
</table>
</center>
<p>Suppose we train a binary classifier on the following dataset where <span class="math inline">\(y\)</span> is the set of true labels, and <span class="math inline">\(\hat{y}\)</span> is the set of predicted labels:</p>
<center>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;"><span class="math inline">\(y\)</span></th>
<th style="text-align: center;">0</th>
<th style="text-align: center;">0</th>
<th style="text-align: center;">0</th>
<th style="text-align: center;">0</th>
<th style="text-align: center;">0</th>
<th style="text-align: center;">1</th>
<th style="text-align: center;">1</th>
<th style="text-align: center;">1</th>
<th style="text-align: center;">1</th>
<th style="text-align: center;">1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\hat{y}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
</tbody>
</table>
</center>
<section id="a-3" class="level3" data-number="12.5.1">
<h3 data-number="12.5.1" class="anchored" data-anchor-id="a-3"><span class="header-section-number">12.5.1</span> (a)</h3>
<p>Fill out the confusion matrix for the given data. <em>Hint:</em> The first row contains the true negatives and false positives, and the second row contains false negatives and true positives (in that order).</p>
<center>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">TN: &nbsp;</th>
<th style="text-align: center;">FP: &nbsp;</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><strong>FN:</strong> &nbsp;</td>
<td style="text-align: center;"><strong>TP:</strong> &nbsp;</td>
</tr>
</tbody>
</table>
</center>
<details>
<summary>
<b>Answer</b>
</summary>
<center>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">TN: 1</th>
<th style="text-align: center;">FP: 4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><strong>FN: 3</strong></td>
<td style="text-align: center;"><strong>TP: 2</strong></td>
</tr>
</tbody>
</table>
</center>
</details>
</section>
<section id="b-3" class="level3" data-number="12.5.2">
<h3 data-number="12.5.2" class="anchored" data-anchor-id="b-3"><span class="header-section-number">12.5.2</span> (b)</h3>
<p>The precision of our classifier. Write your answer as a simplified fraction.</p>
<details>
<summary>
<b>Answer</b>
</summary>
<p><span class="math inline">\(\text{Precision} = \frac{TP}{TP + FP} = \frac{2}{2 + 4} = \frac{1}{3}\)</span></p>
</details>
</section>
<section id="c-2" class="level3" data-number="12.5.3">
<h3 data-number="12.5.3" class="anchored" data-anchor-id="c-2"><span class="header-section-number">12.5.3</span> (c)</h3>
<p>The recall of our classifier. Write your answer as a simplified fraction.</p>
<details>
<summary>
<b>Answer</b>
</summary>
<p><span class="math inline">\(\text{Recall} = \frac{TP}{TP + FN} = \frac{2}{2+3} \frac{2}{5}\)</span></p>
</details>
</section>
<section id="d-1" class="level3" data-number="12.5.4">
<h3 data-number="12.5.4" class="anchored" data-anchor-id="d-1"><span class="header-section-number">12.5.4</span> (d)</h3>
<p><strong>(Discussion)</strong> It is revealed that this dataset describes the results of an algorithm used to predict whether someone is at risk of developing a severe disease with expensive treatment. You are tasked with improving the classifier. Which metrics should you aim to optimize for (Accuracy/Precision/Recall)? Explain your reasoning. (Things to consider: cost of treatment, the severity of disease)</p>
<details>
<summary>
<b>Answer</b>
</summary>
<p>There is no singular correct answer, but here are some examples of reasons.</p>
<ul>
<li><p><strong>Accuracy</strong>: Since this dataset is fairly balanced, accuracy is not too bad of a metric. (3/10). The main flaw of using accuracy as the metric is that it is agnostic towards the original class of the data point when evaluating performance.</p></li>
<li><p><strong>Precision</strong>: Optimizing for precision means that we care more about making sure the positives we output are truly positive. In this setting, we want to ensure that the people we predict to have the disease truly have the disease. If the cost of treatment is very expensive, we don’t want to overburden people who may not have this disease financially.</p></li>
<li><p><strong>Recall</strong>: Optimizing for recall means we care more about detecting all the true positives from the dataset. In this setting, we want to make sure that almost everyone who has the disease knows they have it. If the disease is particularly deadly, then we would be aiming to save the most lives.</p></li>
</ul>
</details>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation column-body">
  <div class="nav-page nav-page-previous">
      <a href="../disc10/disc10.html" class="pagination-link" aria-label="SQL (will update once code works)">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">SQL (will update once code works)</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> Logistic Regression</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="an">execute:</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co">  echo: true</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: true</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-title: Logistic Regression</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co">    page-layout: full</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co">    theme:</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co">      - cosmo</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co">      - cerulean</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co">    callout-icon: false</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> python3</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="fu">## [Link to Slides](https://docs.google.com/presentation/d/1Uity00kUjV7JK2PUXR3LvIb0tIxF2y74bGXA4pYGwOg/edit?usp=sharing)</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="fu">## Logistic Regression</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>Suppose we are given the following dataset, with two features ($\Bbb{X}_{:, 0}$ and $\Bbb{X}_{:, 1}$) and one binary response variable ($y$)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>&lt;center&gt;</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>|$\mathbb{X}_{:, 0}$ | $\mathbb{X}_{:, 1}$ | $y$ |</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>| :-: | :-: | :-: |</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>| 2 | 2 | 0 |</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>| 1 | -1 | 1 |</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>&lt;/center&gt;</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>Here, $\vec{x}^T$ corresponds to a single row of our data matrix, not including the $y$ column. Thus, we can write $\vec{x}_1^T$ as $\vec{x}_1^T = \left<span class="co">[</span><span class="ot">2 \quad 2\right</span><span class="co">]</span>$. Note that there is no intercept term!</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>Suppose you run a Logistic Regression model to determine the probability that $Y=1$ given $\vec{x}$. We denote probability as $P_{\hat{\theta}}$ as opposed to just $P$ to show that $\hat{\theta}$ is a \textit{learned parameter} like it is in OLS, where we denote our function as $f_{\theta}(x)$.</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>$$P_{\hat{\theta}}(Y=1|\vec{x}) = \sigma(\vec{x}^T \theta) = \frac{1}{1 + \exp(- \vec{x}^T \theta)}$$</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>Your algorithm learns that the optimal $\hat\theta$ value is $\hat\theta = \left<span class="co">[</span><span class="ot">-\frac{1}{2} \quad-\frac{1}{2}\right</span><span class="co">]</span>^T$.</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="fu">### (a)</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>$\sigma(z)$ is called a "sigmoid" function with the equation $$\sigma(z) = \frac{1}{1 + \exp(-z)}$$ for some arbitrary real number $z$. What is the range of possible values for $\sigma(\cdot)$?</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>&lt;details&gt;</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>&lt;summary&gt;&lt;b&gt;Answer&lt;/b&gt;&lt;/summary&gt;</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$x \to -\infty: \frac{1}{1 + e^{-z}} \to 0$</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$x \to \infty: \frac{1}{1 + e^{-z}} \to \frac{1}{1 + 0} = 1$</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>$0 &lt; \sigma(z) &lt; 1$. Note that the sigmoid function can never *equal* 0 or 1.</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>&lt;/details&gt;</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a><span class="fu">### (b)</span></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>Calculate $P_{\hat{\theta}}(Y=1|\vec{x}^T=\left<span class="co">[</span><span class="ot">1 \quad   0\right</span><span class="co">]</span>)$.</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>&lt;details&gt;</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>&lt;summary&gt;&lt;b&gt;Answer&lt;/b&gt;&lt;/summary&gt;</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>Calculate $\vec{x}^T\hat{\theta}$ first:</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>    \vec{x}^T\hat{\theta} &amp;= \begin{bmatrix}1 &amp; 0\end{bmatrix}\begin{bmatrix} -\frac{1}{2} <span class="sc">\\</span> -\frac{1}{2} \end{bmatrix}<span class="sc">\\</span></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>    &amp;= 1*-\frac{1}{2} + 0*-\frac{1}{2}<span class="sc">\\</span></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>    &amp;= -\frac{1}{2}</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>We can then plug this into the sigmoid function:</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>    \sigma(-\frac{1}{2}) &amp;= \frac{1}{1 + e^{\frac{1}{2}}}<span class="sc">\\</span></span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>    &amp;\approx 0.38</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>&lt;/details&gt;</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a><span class="fu">### (c)</span></span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>Using a threshold of $T = 0.5$, what would our algorithm classify $y$ as given the results of part b?</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>&lt;details&gt;</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>&lt;summary&gt;&lt;b&gt;Answer&lt;/b&gt;&lt;/summary&gt;</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>Our $p$ of $0.38$ is *smaller* than the threshold of $0.5$, so our algorithm would classify $y$ as class $0$.</span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a>A **Decision Rule** tells us how to classify a data point:</span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a>$$\hat{y} = </span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a>\text{Class 1} &amp;\text{if } \quad p \geq T<span class="sc">\\</span></span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a>\text{Class 0} &amp;\text{if } \quad p \lt T</span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a>&lt;/details&gt;</span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a><span class="fu">### (d)</span></span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a>The empirical risk using cross-entropy loss is given by the following expression. Remember, whenever you see $\log$ in this course, you must assume the natural logarithm (base-$e$) unless explicitly told otherwise.</span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a>    R(\theta) &amp;= -\dfrac{1}{n} \sum_{i=1}^{n} \big( y_i \log P_{\theta}(Y=1|\vec{x_i}) + (1-y_i) \log  P_{\theta}(Y=0|\vec{x_i}) \big)</span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a>\end{align*} </span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a> Suppose we run a different algorithm and obtain $\hat\theta_{new} = \left<span class="co">[</span><span class="ot">0 \quad 0\right</span><span class="co">]</span>^T$. Calculate the empirical risk for $\hat\theta_{new}$ on our dataset.</span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a>&lt;details&gt;</span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a>&lt;summary&gt;&lt;b&gt;Answer&lt;/b&gt;&lt;/summary&gt;</span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a>    R(\hat\theta_{new}) &amp;= -\dfrac{1}{2} \sum_{i=1}^{2} \big( y_i \log P_{\hat{\theta_{new}}}(Y=1|\vec{x_i}) + (1-y_i) \log  P_{\hat{\theta_{new}}}(Y=0|\vec{x_i}) )<span class="sc">\\</span></span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a>    &amp;= -\frac{1}{2} <span class="co">[</span><span class="ot">(0 \log P_{\hat{\theta_{new}}}(Y=1|\vec{x_1}) + 1 \log  P_{\hat{\theta_{new}}}(Y=0|\vec{x_1})) + \\ &amp; (1 \log P_{\hat{\theta_{new}}}(Y=1|\vec{x_2}) + 0 \log  P_{\hat{\theta_{new}}}(Y=0|\vec{x_2}))</span><span class="co">]</span> <span class="sc">\\</span></span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a>    &amp;= -\frac{1}{2} (\log P_{\hat{\theta_{new}}}(Y=0|\vec{x_1}) + \log P_{\hat{\theta_{new}}}(Y=1|\vec{x_2})) <span class="sc">\\</span></span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a>    &amp;= -\frac{1}{2} (\log (1 - \sigma(0)) + \log \sigma(0)) <span class="sc">\\</span> </span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a>    &amp;= -\log(0.5) = \log 2 \approx 0.693</span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a>Notice that the inputs to the sigmoid function are $0$ because $\hat{\theta}_{new}$ is the zero vector, making all $\vec{x}^T\hat{\theta}_{new} = 0$</span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a>&lt;/details&gt;</span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a><span class="fu">## Linearly Separable Data</span></span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a>Suppose we have two different Logistic Regression models, A and B, and we run gradient descent for 1000 steps to obtain the model parameters $\hat\theta_A = \left<span class="co">[</span><span class="ot">-\frac{1}{2} \quad-\frac{1}{2}\right</span><span class="co">]</span>^T$ and $\hat\theta_B = \left<span class="co">[</span><span class="ot">0 \quad0\right</span><span class="co">]</span>^T$. How do they compare?</span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a>The dataset is reproduced below for your convenience.</span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a>&lt;center&gt;</span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a>|$\mathbb{X}_{:, 0}$ | $\mathbb{X}_{:, 1}$ | $y$ |</span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a>| :-: | :-: | :-: |</span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a>| 2 | 2 | 0 |</span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a>| 1 | -1 | 1 |</span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a>&lt;/center&gt;</span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a><span class="fu">### (a)</span></span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a>Is our dataset linearly separable? If so, write the equation of a hyperplane that separates the two classes. Otherwise, briefly explain why not (Hint: draw the two data points).</span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a>&lt;details&gt;</span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a>&lt;summary&gt;&lt;b&gt;Answer&lt;/b&gt;&lt;/summary&gt;</span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a>Yes, the line $\mathbb{X}_{:, 1} = 0$ (line on horizontal axis) separates the data in feature space!</span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a>&lt;center&gt;&lt;img src = "images/q2a.png" width = 500&gt;&lt;/center&gt;</span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a>&lt;/details&gt;</span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a><span class="fu">### (b)</span></span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a>If we let gradient descent keep running indefinitely for our two models, will either of them converge given the design matrix above? Why? If not, how can we remedy this?</span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a>&lt;details&gt;</span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a>&lt;summary&gt;&lt;b&gt;Answer&lt;/b&gt;&lt;/summary&gt;</span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a>No.</span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a>Our dataset is linearly separable, so the *optimal* cross-entropy loss is 0. However, a cross-entropy loss of 0 can never be achieved. Remember that $\sigma(z)$ never outputs *exactly* 0 or 1, but it can get arbitrarily close! </span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a>Hence, no single value of $\theta$ will ever "minimize" cross-entropy loss (ie. let $\sigma(x^T \theta) = 0$), but gradient descent can bring the cross-entropy loss closer and closer to 0 as $\theta$ goes to $\pm \infty$.</span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a>To avoid our absolute values of the weights diverging to $\infty$, we can regularize our cross-entropy loss and penalize arbitrarily large $\theta$! </span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a>&lt;/details&gt;</span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a><span class="fu">### (c)</span></span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a>Assume we add the data point $<span class="co">[</span><span class="ot">3, -2</span><span class="co">]</span>$ to the design matrix such that our resulting design matrix is as follows:</span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a>&lt;center&gt;</span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a>| $\mathbb{X}_{:, 0}$ | $\mathbb{X}_{:, 1}$ | $y$ |</span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a>| :-: | :-: | :-: |</span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a>| 2 | 2 | 0 |</span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a>| 1 | -1 | 1 |</span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a>| 3 | -2 | 0 |</span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a>&lt;/center&gt;</span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a>Is it possible to achive a perfect accuracy using logistic regression?</span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a>&lt;details&gt;</span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a>&lt;summary&gt;&lt;b&gt;Answer&lt;/b&gt;&lt;/summary&gt;</span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a>The data is still linearly separable, so we can train a logistic regression model to achieve perfect accuracy! For example, $\mathbb{X}_{:, 0} = 1.5$ would result in perfect accuracy.</span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a>&lt;center&gt;&lt;img src = "images/q2c.png" width = 500&gt;&lt;/center&gt;</span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a>&lt;/details&gt;</span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a><span class="fu">## ROC Curves</span></span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a>Consider the following ROC (receiver operating characteristic) curves that were each created from different models. </span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a>&lt;center&gt;&lt;img src="images/roc.png" width = 500&gt;&lt;/center&gt;</span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a><span class="fu">### (a)</span></span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a>Compare the Area Under the Curve (AUC) of Line 1 and Line 4. What kind of model would predict Line 1? What kind of model would predict Line 4? </span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a>&lt;details&gt;</span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a>&lt;summary&gt;&lt;b&gt;Answer&lt;/b&gt;&lt;/summary&gt;</span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a>Line 1 (solid black line) is known as a "perfect predictor"; it always predicts the correct class for $y$, so its true positive rate (TPR) is 1, and its false positive rate (FPR) is 0. Because we want our classifier to be as close as possible to the perfect predictor, we aim to maximize the AUC.</span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a>On the other hand, Line 4 (solid grey line) is a random predictor that predicts $y=1$ with a probability of 0.5 and $y=0$ with a probability of 0.5. It's AUC = 0.5, and it does no better than a random coin flip (proof in course notes).</span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a>&lt;/details&gt;</span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a><span class="fu">### (b)</span></span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a>Suppose we fix the decision threshold for all 4 models such that we get an FPR of 0.1 when we evaluate our model. In order of most to least preferred, rank models given their ROC curve. </span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a>&lt;details&gt;</span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a>&lt;summary&gt;&lt;b&gt;Answer&lt;/b&gt;&lt;/summary&gt;</span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a>Since the FPR is now fixed at 0.1, the only thing that we can adjust is the TPR. To determine the most to least preferred model, we look at each model's TPR at an FPR of 0.1. Higher TPRs are better because they indicate that a greater proportion of true positive cases are correctly identified by the model. Hence, we get the following ranking: </span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a>$$\text{Line 1} &gt; \text{Line 3} &gt;\text{Line 2} &gt;\text{Line 4} $$</span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a>&lt;/details&gt;</span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a><span class="fu">## Performance Metrics</span></span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a>Here are some classification performance metrics (from Fall 2023 Final Reference Sheet):</span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a>&lt;center&gt;</span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a>| Metric | Formula | Other Names |</span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a>| :-: | :-: | :-: |</span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a>| Accuracy | $\frac{TP+TN}{n}$ | |</span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a>| Precision | $\frac{TP}{TP + FP}$ | |</span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a>| Recall/TPR | $\frac{TP}{TP + FN}$ | True Positive Rate, Sensitivity |</span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a>| FPR | $\frac{FP}{FP + TN}$ | False Positive Rate, Specificity |</span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a>&lt;/center&gt;</span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a>Suppose we train a binary classifier on the following dataset where $y$ is the set of true labels, and $\hat{y}$ is the set of predicted labels:</span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a>&lt;center&gt;</span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a>| $y$ | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 1 |</span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a>| :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: |</span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a>| $\hat{y}$ | 0 | 1 | 1 | 1 | 1 | 1 | 1 | 0 | 0 | 0 |</span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a>&lt;/center&gt;</span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a><span class="fu">### (a)</span></span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a>Fill out the confusion matrix for the given data.</span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a>*Hint:* The first row contains the true negatives and false positives, and the second row contains false negatives and true positives (in that order).</span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a>&lt;center&gt;</span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a>| TN: <span class="dv">&amp;nbsp;</span>| FP: <span class="dv">&amp;nbsp;</span>|</span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a>| :-: | :-: |</span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a>| **FN:** &amp;nbsp;| **TP:** <span class="dv">&amp;nbsp;</span>|</span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a>&lt;/center&gt;</span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a>&lt;details&gt;</span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a>&lt;summary&gt;&lt;b&gt;Answer&lt;/b&gt;&lt;/summary&gt;</span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a>&lt;center&gt;</span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a>| TN: 1| FP: 4|</span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a>| :-: | :-: |</span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a>| **FN: 3** | **TP: 2** |</span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a>&lt;/center&gt;</span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a>&lt;/details&gt;</span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a><span class="fu">### (b)</span></span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a>The precision of our classifier. Write your answer as a simplified fraction.</span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a>&lt;details&gt;</span>
<span id="cb1-274"><a href="#cb1-274" aria-hidden="true" tabindex="-1"></a>&lt;summary&gt;&lt;b&gt;Answer&lt;/b&gt;&lt;/summary&gt;</span>
<span id="cb1-275"><a href="#cb1-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-276"><a href="#cb1-276" aria-hidden="true" tabindex="-1"></a>$\text{Precision} = \frac{TP}{TP + FP} = \frac{2}{2 + 4} = \frac{1}{3}$</span>
<span id="cb1-277"><a href="#cb1-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-278"><a href="#cb1-278" aria-hidden="true" tabindex="-1"></a>&lt;/details&gt;</span>
<span id="cb1-279"><a href="#cb1-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-280"><a href="#cb1-280" aria-hidden="true" tabindex="-1"></a><span class="fu">### (c)</span></span>
<span id="cb1-281"><a href="#cb1-281" aria-hidden="true" tabindex="-1"></a>The recall of our classifier. Write your answer as a simplified fraction.</span>
<span id="cb1-282"><a href="#cb1-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-283"><a href="#cb1-283" aria-hidden="true" tabindex="-1"></a>&lt;details&gt;</span>
<span id="cb1-284"><a href="#cb1-284" aria-hidden="true" tabindex="-1"></a>&lt;summary&gt;&lt;b&gt;Answer&lt;/b&gt;&lt;/summary&gt;</span>
<span id="cb1-285"><a href="#cb1-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-286"><a href="#cb1-286" aria-hidden="true" tabindex="-1"></a>$\text{Recall} = \frac{TP}{TP + FN} = \frac{2}{2+3} \frac{2}{5}$</span>
<span id="cb1-287"><a href="#cb1-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-288"><a href="#cb1-288" aria-hidden="true" tabindex="-1"></a>&lt;/details&gt;</span>
<span id="cb1-289"><a href="#cb1-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-290"><a href="#cb1-290" aria-hidden="true" tabindex="-1"></a><span class="fu">### (d)</span></span>
<span id="cb1-291"><a href="#cb1-291" aria-hidden="true" tabindex="-1"></a>**(Discussion)** It is revealed that this dataset describes the results of an algorithm used to predict whether someone is at risk of developing a severe disease with expensive treatment. You are tasked with improving the classifier. Which metrics should you aim to optimize for (Accuracy/Precision/Recall)? Explain your reasoning. (Things to consider: cost of treatment, the severity of disease)</span>
<span id="cb1-292"><a href="#cb1-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-293"><a href="#cb1-293" aria-hidden="true" tabindex="-1"></a>&lt;details&gt;</span>
<span id="cb1-294"><a href="#cb1-294" aria-hidden="true" tabindex="-1"></a>&lt;summary&gt;&lt;b&gt;Answer&lt;/b&gt;&lt;/summary&gt;</span>
<span id="cb1-295"><a href="#cb1-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-296"><a href="#cb1-296" aria-hidden="true" tabindex="-1"></a>There is no singular correct answer, but here are some examples of reasons.</span>
<span id="cb1-297"><a href="#cb1-297" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-298"><a href="#cb1-298" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Accuracy**: Since this dataset is fairly balanced, accuracy is not too bad of a metric. (3/10). The main flaw of using accuracy as the metric is that it is agnostic towards the original class of the data point when evaluating performance. </span>
<span id="cb1-299"><a href="#cb1-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-300"><a href="#cb1-300" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Precision**: Optimizing for precision means that we care more about making sure the positives we output are truly positive. In this setting, we want to ensure that the people we predict to have the disease truly have the disease. If the cost of treatment is very expensive, we don't want to overburden people who may not have this disease financially.</span>
<span id="cb1-301"><a href="#cb1-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-302"><a href="#cb1-302" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Recall**: Optimizing for recall means we care more about detecting all the true positives from the dataset. In this setting, we want to make sure that almost everyone who has the disease knows they have it. If the disease is particularly deadly, then we would be aiming to save the most lives. </span>
<span id="cb1-303"><a href="#cb1-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-304"><a href="#cb1-304" aria-hidden="true" tabindex="-1"></a>&lt;/details&gt;</span>
<span id="cb1-305"><a href="#cb1-305" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>